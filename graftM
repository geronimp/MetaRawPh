#!/usr/bin/env python


##### ##### ##### ##### ##### ##### ##### #####
#                                             #
#                 graftM v.0.2                #
#                                             #
#        This is a script for doing the       #
#       gene centric analyses in Joel's       #
#               Honours project.              #
#                                             #
##### ##### ##### ##### ##### ##### ##### #####

##### Messsages #####
intro = '''
## graftM  v.0.2                     ##
## Searches raw sequences for genes  ##
## Joel Boyd, Honours 2014           ##
'''

import argparse
import re
from Bio import SeqIO
import math
import glob
import subprocess
import os.path
from datetime import datetime
import cPickle as pickle
import code



##### Input Files #####

parser = argparse.ArgumentParser(description='''--- graftM  v.0.2 --- Searches reads for genes using hmms, and places them into a tree with pplacer to classify them phylogenetically.'''
                          , epilog='Joel Boyd - Honours 2014.')
parser.add_argument('-f', metavar = 'forward read (or single read file)', type = str, nargs = 1 , help = 'Forward raw sequence file in .fa, or .fq.gz format.', required = True)
parser.add_argument('-r', metavar = 'reverse read', type = str, nargs = 1, help = 'Optional reverse raw sequence file in .fa, or .fq.gz format.', default = argparse.SUPPRESS)
parser.add_argument('-t', metavar = 'prot or dna', type = str, nargs = 1, help = 'dna (like 16S) or prot (like mcrA)', choices = ['prot','dna'], required = True)
parser.add_argument('-m', metavar = 'hmm_file', type = str, nargs = 1, help = 'HMM file', required = True)
parser.add_argument('-e', metavar = 'evalue', type = str, nargs = 1, help = 'evalue cutoff for the hmmsearch (default = 1e-5)', default = ['1e-5'])
parser.add_argument('-jpplacer', metavar = 'threads', type = str, nargs = 1, help = 'number of threads to use when pplacing (default = 5)', default = [5])
parser.add_argument('-jhmm', metavar = 'threads', type = str, nargs = 1, help = 'number of threads to use when hmmsearching (default = 5)', default = [5])
parser.add_argument('-d', metavar = 'confidence', type = str, nargs = 1, help = 'Cutoff of placement confidence level (0.5 - 1), default = 0.75', default = [0.75])
parser.add_argument('-c', metavar = 'reference_package', type = str, nargs = 1, help = 'Reference package of gene family', default =argparse.SUPPRESS)
parser.add_argument('-g', metavar = 'gg_database', type = str, nargs = 1, help = 'Aligned gg database for pynast alignment (dna sequences only)', default = argparse.SUPPRESS)
parser.add_argument('-o', metavar = 'output directory', type = str, nargs = 1, help = 'Specify an output directory (default is the file name) If you are looking for more than one marker gene in the same directory, you will definitely need this flag to avoid clobbering.', default = argparse.SUPPRESS)
parser.add_argument('-v', action = 'version', version = 'graftM v.0.2')

cl=parser.parse_args()

if float(cl.d[0]) < float(0.5):
  message('Please specify a confidence level (-d) between 0.5 and 1.0!')
  exit(1)
elif float(cl.d[0]) > float(1.0):
  message('Please specify a confidence level (-d) between 0.5 and 1.0!')
  print cl.d[0]
  exit(1)

if cl.e[0]:
  cl.e[0] = '-E '+cl.e[0]
else:
  pass

if cl.jpplacer[0]:
  cl.jpplacer[0] =  '-j '+str(cl.jpplacer[0])
else:
  pass

if cl.jhmm[0]:
  cl.jhmm[0] = '--cpu '+str(cl.jhmm[0])
else:
  pass

##### Functions #####

# splits fasta file for hmmaligning
def fasta_parser(to_split):
  num_seqs = 1
  all_fasta = list(SeqIO.parse(to_split, 'fasta'))
  num_files = int(math.ceil(len(all_fasta)/float(num_seqs)))
  i = 1
  if to_split.startswith('./'):
    to_name = to_split.replace('./', '')
    while i <= num_files:
      start = int(i-1) * int(num_seqs)
      end = int(i) * int(num_seqs)
      filename = to_name.split('.')[0] + '_' + str(i) + '.g.fasta'
      SeqIO.write(all_fasta[start:end], filename, 'fasta')
      i += 1
  if to_split.startswith('../'):
    to_name = to_split.replace('../', '')
    while i <= num_files:
      start = int(i-1) * int(num_seqs)
      end = int(i) * int(num_seqs)
      filename = '../' + to_name.split('.')[0] + '_' + str(i) + '.g.fasta'
      SeqIO.write(all_fasta[start:end], filename, 'fasta')
      i += 1
  else:
    while i <= num_files:
      start = int(i-1) * int(num_seqs)
      end = int(i) * int(num_seqs)
      filename = to_split.split('.')[0] + '_' + str(i) + '.g.fasta'
      SeqIO.write(all_fasta[start:end], filename, 'fasta')
      i += 1

# Displays message with time in brackets before the message.
def message(message):
  time = datetime.now().strftime('%H:%M:%S')
  print '['+time+']: '+message

# split_names
def title_cleaner(title):
  d = title.split('_')
  del d[-1]
  return '_'.join(d)

# run nhmmer
def nhmmer(hmm, seq_file_list):
  suffix = ['_for', '_rev']
  table_title_list = []
  for seq_file in seq_file_list:
    hmmout_table_title = replace_name(seq_file, suffix[0]+'.hmmout.csv')
    table_title_list.append(hmmout_table_title)
    if seq_file.endswith(('.fa','.faa','.fna')):
      subprocess.check_call(["/bin/bash", "-c", " nhmmer "+cl.jhmm[0]+" "+cl.e[0]+" --tblout " +hmmout_table_title+ " " +hmm+ " <(sed 's/:/$/g' " +seq_file+ ") 2>&1 > /dev/null"])
    elif seq_file.endswith(('.fq.gz', 'fastq.gz')):
      subprocess.check_call(["/bin/bash", "-c", " nhmmer "+cl.jhmm[0]+" "+cl.e[0]+" --tblout " +hmmout_table_title+ " " +hmm+ " <(awk '{print \">\" substr($0,2);getline;print;getline;getline}' <(zcat " +seq_file+ " | sed 's/:/$/g')) 2>&1 > /dev/null"])
    else:
      message('ERROR: Suffix on %s not recegnised. Please submit an .fq.gz or .fa file\n' % (seq_file))
      exit(1)
    del suffix[0]
  return table_title_list

# run hmmsearch
def hmmsearch(hmm, seq_file_list):
  suffix = ['_for', '_rev']
  table_title_list = []
  for seq_file in seq_file_list:
    hmmout_table_title = replace_name(seq_file, suffix[0]+'.hmmout.csv')
    table_title_list.append(hmmout_table_title)
    if seq_file.endswith(('.fa','.faa','.fna')):
      subprocess.check_call(["/bin/bash", "-c", " hmmsearch "+cl.jhmm[0]+" "+cl.e[0]+" --domtblout " +hmmout_table_title+ " " +hmm+ " <(getorf -sequence  <(sed 's/:/$/g' " +seq_file+ ") -outseq >(cat) -minsize 98 2>/dev/null) 2>&1 > /dev/null"])
    elif seq_file.endswith(('.fq.gz', 'fastq.gz')):
      subprocess.check_call(["/bin/bash", "-c", " hmmsearch "+cl.jhmm[0]+" "+cl.e[0]+" --domtblout " +hmmout_table_title+ " " +hmm+ " <(getorf -sequence <(awk '{print \">\" substr($0,2);getline;print;getline;getline}' <(zcat " +seq_file+ " | sed 's/:/$/g')) -outseq >(cat) -minsize 98 2>/dev/null) 2>&1 > /dev/null"])
    else:
      message('ERROR: Suffix on %s not recegnised. Please submit an .fq.gz or .fa file\n' % (seq_file))
      exit(1)
    del suffix[0]
  return table_title_list

# run pynast
def pynast(ts_file, gg_db_path):
  subprocess.check_call('pynast -l 0 -i ' +replace_name(ts_file, '.fna.fasta')+ ' -t ' +gg_db_path+ ' -a ' +replace_name(ts_file, '.aln.fasta'), shell=True)

# run pplacer
def pplacer(refpkg, ts_file):
  subprocess.check_call('pplacer '+cl.jpplacer[0]+' --verbosity 0 -c ' +refpkg+ ' ' +ts_file, shell=True)

# run guppy classify
def guppy_class(rpkg, jplace_file):
  subprocess.check_call('guppy classify -c ' +rpkg+ ' '+jplace_file+' > ' +replace_name(jplace_file, '.guppy'), shell=True)

# delete
def delete(delete_list):
  for item in delete_list:
    subprocess.check_call("rm "+item, shell = True)

# HMM aligning
def hmmalign(hmm, sequencefile):
  base_name = replace_name(sequencefile, '')
  try:
    str(cl.o[0])
    subprocess.check_call("mkdir "+ cl.o[0], shell=True)
  except:
    subprocess.check_call("mkdir "+ base_name, shell = True)
  try:
    str(cl.o[0])
    subprocess.check_call("mv "+base_name+".* "+cl.o[0], shell = True)
  except:
    subprocess.check_call("mv " +base_name+".*  "+base_name+"/", shell = True)
  if cl.t[0] == 'prot':
    try:
      str(cl.o[0])
      fasta_parser((cl.o[0]+'/'+replace_name(sequencefile, '.orf.fasta')))
    except:
      fasta_parser((base_name+'/'+replace_name(sequencefile, '.orf.fasta')))
  path = './'+out_file_name+'/*.g.fasta'
  files = glob.glob(path)
  for file in files:
    subprocess.check_call('hmmalign --trim -o '+file+'.sto ' +hmm+ ' ' +file, shell = True)
  path = './'+out_file_name+'/*.sto'
  files = glob.glob(path)
  for file in files:
    subprocess.check_call('seqmagick convert ' +file+ ' ' +file+'_conv_.fa', shell=True)
  path = './'+out_file_name+'/*_conv_.fa'
  files = glob.glob(path)
  for file in files:
    subprocess.check_call("sed 's/[a-z]//g' " +file+ " > " +file+'.ready', shell=True)
  try:
    str(cl.o[0])
    subprocess.check_call("for f in "+cl.o[0]+"/*.sto; do rm \"$f\"; done ", shell = True)
    subprocess.check_call("for f in "+cl.o[0]+"/*conv_.fa; do rm \"$f\"; done ", shell = True)
    subprocess.check_call("for f in "+cl.o[0]+"/*.fasta; do rm \"$f\"; done ", shell = True)
  except:
    subprocess.check_call("for f in "+base_name+"/*.sto; do rm \"$f\"; done ", shell=True)
    subprocess.check_call("for f in "+base_name+"/*conv_.fa; do rm \"$f\"; done ", shell=True)
    subprocess.check_call("for f in "+base_name+"/*.fasta; do rm \"$f\"; done ", shell=True)
  path = './'+out_file_name+'/*.ready'
  files = glob.glob(path)
  out_aligned_name = replace_name(sequencefile, '.aln.fasta')
  title_file_open = open(out_aligned_name, 'w')
  for file in files:
    for line in open(file):
      title_file_open.write(line)
  title_file_open.close()
  subprocess.check_call('rm '+out_file_name+'/*.ready', shell=True)

# process hmmsearch/nhmmer results into ts_files
def csv_to_titles(hmm_table_list, type_):
  titles_list = []
  reads_list = []
  write_list = []
  title_count = 0
  for hmm_table in hmm_table_list:
    for line in open(hmm_table):
      if line.startswith('#'):
        continue
      else:
        title_count += 1
        title = str(line.split(' ', 1)[0])
        if type_ == 'dna':
          if 'FCC' in line:
            titles_list.append(title.replace('$',':').replace('_', '/'))
          else:
            titles_list.append(title.replace('$',':'))
        if type_ == 'prot':
          if line.startswith('FCC'):
            titles_list.append(title_cleaner(title).replace('$',':')[:-2])
          else:
            titles_list.append(title_cleaner(title).replace('$',':'))
    reads_list.append(titles_list)
    titles_list = []

  if title_count == 0:
    message('0 Reads found!')
    exit(1)
  else:
    message('Found %s read(s) in %s.' % (str(title_count), replace_name(hmm_table_list[0], '')))

  if len(reads_list) == 2:
    for_r = set(reads_list[0])
    for read in reads_list[1]:
      if read in for_r:
        write_list.append(read)
  elif len(reads_list) == 1:
    write_list = reads_list[0]

  output_file_name = replace_name(hmm_table_list[0], '')[:-3]+'readnames.txt'
  output_file = open(output_file_name, 'w')
  for name in write_list:
    if name.startswith('FCC'):
      output_file.write(name+'/1'+'\n')
    else:
      output_file.write(name+'\n')
  output_file.close()

  return output_file_name

def extract_from_raw_reads(raw_seq_file, hmm, name_file):
  sequence_file_name = name_file.replace('_readnames.txt', '.fna')
  if raw_seq_file.endswith(('.fa','.faa','.fna')):
    message('Extracting reads..')
    subprocess.check_call("fxtract -H -f " +replace_name(raw_seq_file, '_readnames.txt')+ " " +raw_seq_file+ " > " +sequence_file_name+ " ", shell=True)
  if raw_seq_file.endswith(('.fq.gz', 'fastq.gz')):
    message('Extracting reads..')
    subprocess.check_call("fxtract -H -f " +replace_name(raw_seq_file, '_readnames.txt')+ " " +raw_seq_file+ " | awk '{print \">\" substr($0,2);getline;print;getline;getline}' > " +sequence_file_name+ " ", shell=True)
  alt_title_file_name = replace_name(raw_seq_file, '.fna.fasta')
  fasta_file_open = open(alt_title_file_name, 'w')
  for line in open(sequence_file_name):
    if '>' in line:
      line = line.replace(':', '_')
      fasta_file_open.write(line)
    else:
      line = line
      fasta_file_open.write(line)
  fasta_file_open.close()
  if cl.t[0] == 'dna':
    return
  raw_orf_title = replace_name(raw_seq_file, '.orf')
  subprocess.check_call('getorf -sequence ' +alt_title_file_name+ ' -outseq ' +raw_orf_title+ ' -minsize 98 2>/dev/null', shell=True)
  hmm_out_title = replace_name(raw_seq_file, '.tmp.csv')
  subprocess.check_call("hmmsearch --tblout "+hmm_out_title+" "+hmm+" "+raw_orf_title+" 2>&1 > /dev/null", shell=True)

  raw_titles = []
  for line in open(hmm_out_title):
    if line.startswith('#'):
      continue
    else:
      split = line.split(' ', 1)
      raw_titles.append(split[0])
  file_name = replace_name(raw_seq_file, '.orf.titles')
  title_file_open = open(file_name, 'w')
  for title in raw_titles:
    title = str(title) + '\n'
    title_file_open.write(title)
  title_file_open.close()
  hmm_out_title = replace_name(raw_seq_file, '.orf.fasta')
  subprocess.check_call('fxtract -H -f '+file_name+' '+raw_orf_title+' > '+hmm_out_title, shell=True)

def replace_name(old_title,new_suffix):
  if '/' in old_title:
    split = old_title.split('/')
    title2 = split[len(split) - 1]
    if '.' in title2:
      split = title2.split('.')
      return split[0] + new_suffix
    else:
      return 'Suffix on '+old_title+' not recognized.'
  else:
    if '.' in old_title:
      split = old_title.split('.')
      return split[0] + new_suffix
    else:
      return old_title

def gg_formatter(read_name, classification):
  ids = ['k_','p_','c_','o_','f_','g_','s_','i_']
  classification.remove(classification[0])
  for x in range(0, 7):
    try:
      classification[x] = ids[x]+classification[x]
    except:
      classification.append(ids[x])
  return classification

 ##### Running Script #####

print intro
seq_file_title = replace_name(cl.f[0], '')
hmm_file_title = replace_name(cl.m[0], '.hmm')

# Defining a list of the reads to be searched & checking the file names match.
try:
  str(cl.r[0])
  if replace_name(cl.f[0], '') != replace_name(cl.r[0], ''):
    message("Looks like the forward reads don't match the reverse reads. Please make sure you're using the right ones!")
    exit(1)
  seq_file_list = [cl.f[0], cl.r[0]]
except AttributeError:
  seq_file_list = [cl.f[0]]

# Check if there is an output folder name specified
try:
  str(cl.o[0])
  out_file_name = cl.o[0]
except AttributeError:
  out_file_name = replace_name(cl.f[0], '')

if cl.t[0] == 'prot':
  date = datetime.now().strftime('%Y/%m/%d')
  message(date)
  message('Searching %s using %s..' % (seq_file_title, hmm_file_title))
  name_file = csv_to_titles(hmmsearch(cl.m[0], seq_file_list), cl.t[0])
  extract_from_raw_reads(cl.f[0], cl.m[0], name_file)
  message('Aligning to hmm..')
  hmmalign(cl.m[0], replace_name(cl.f[0], '.ts.fasta'))
  try:
    str(cl.c[0])
    message('Placing in refpkg tree..')
    pplacer(cl.c[0], replace_name(cl.f[0], '.aln.fasta'))
    message('Creating Guppy file..')
    guppy_class(cl.c[0], replace_name(cl.f[0],'.aln.jplace'))
  except AttributeError:
    message('No refpkg found! Stopping at alignment')
    exit(1)

if cl.t[0] == 'dna':
  date = datetime.now().strftime('%Y-%m-%d')
  message(date)
  message('Searching %s using %s..' % (seq_file_title, hmm_file_title))
  name_file = csv_to_titles(nhmmer(cl.m[0], seq_file_list), cl.t[0])
  extract_from_raw_reads(cl.f[0], cl.m[0], name_file)
  message('Aligning to database..')
  pynast(cl.f[0], cl.g[0])
  try:
    str(cl.c[0])
    message('Placing in refpkg tree..')
    pplacer(cl.c[0], replace_name(cl.f[0],'.aln.fasta'))
    message('Creating Guppy file..')
    guppy_class(cl.c[0], replace_name(cl.f[0], '.aln.jplace'))
  except AttributeError:
    message('No refpkg found! Stopping at alignment')
    exit(1)

d = {
}

test = 1
message('Creating dictionary..')
for line in open(glob.glob(replace_name(cl.f[0],'.guppy'))[0], 'r'):
  list = [x for x in line.split(' ') if x]
  try:
    float(list[4])
    if list[0] != 'name' and list[1] == list[2] and float(list[4]) and float(list[len(list)-2]) > float(cl.d[0]):
      if list[0] not in d:
        d[list[0]] = []
      d[list[0]].append(list[3])
    else:
      continue
  except ValueError:
    list.pop(3)
    if list[0] != 'name' and list[0] not in d and list[1] == list[2] and float(list[4]) and float(list[len(list)-2]) > float(cl.d[0]):
      d[list[0]].append(list[3])
    else:
      continue


message('Saving dictionary..')
pickle.dump(d, open(replace_name(cl.f[0],'.p'), 'wb'))
message('Dictionary for %s complete..' % (seq_file_title))
message('Building OTU table..')

classifications = []
placed = []

for x,y in d.iteritems():
  if x not in placed:
    classifications.append(';'.join(gg_formatter(x,y)))
    placed.append(x)
  else:
    continue

otu_id = 0
output_table = []
unique_list = []
output_table.append('#OTU_ID\t'+replace_name(cl.f[0], '')+'\tConsensusLineage')
for x in classifications:
  if x not in unique_list:
    unique_list.append(x)
for x in unique_list:
  output_table.append([str(otu_id),str(classifications.count(x)),x])
  otu_id += 1

otu_table = open(replace_name(cl.f[0], '_otu_table.txt'), 'w')
for line in output_table:
  if '#' in line:
    otu_table.write(line+'\n')
  else: otu_table.write('\t'.join(line)+'\n')
otu_table.close()

try:
  str(cl.o[0])
  subprocess.call("mv "+replace_name(cl.f[0], '')+"* "+cl.o[0]+"/ 2> /dev/null", shell = True)
except:
  subprocess.call("mv "+replace_name(cl.f[0], '')+"* "+replace_name(cl.f[0], '')+"/ 2> /dev/null", shell = True)

message('Finshed! Thank you for using graftM! \n')

exit(1)
