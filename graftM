#!/usr/bin/env python


##### ##### ##### ##### ##### ##### ##### #####
#                                             #
#                 graftM v.0.1                #
#                                             #
#        This is a script for doing the       #
#       gene centric analyses in Joel's       #
#               Honours project.              #
#                                             #
##### ##### ##### ##### ##### ##### ##### #####

##### Messsages #####
intro = '''
## graftM  v.0.1                     ##
## Searches raw sequences for genes  ##
## Joel Boyd, Honours 2014           ##
'''

import argparse
import re
from Bio import SeqIO
import math
import glob
import subprocess
import os.path
from datetime import datetime
import cPickle as pickle
import code



##### Input Files #####

parser = argparse.ArgumentParser(description='''graftM  v.0.1 searches metagenomic datasets using hmms, and places them into a tree with pplacer to classify them phylogenetically.'''
                          , epilog='Joel Boyd - Honours 2014.')
parser.add_argument('-f', metavar = 'forward read (or single read file)', type = str, nargs = 1 , help = 'Froward raw sequence file in .fa, or .fq.gz format.', required = True)
parser.add_argument('-r', metavar = 'reverse read', type = str, nargs = 1, help = 'Optional reverse raw sequence file in .fa, or .fq.gz format.', default = argparse.SUPPRESS)
parser.add_argument('-t', metavar = 'prot or dna', type = str, nargs = 1, help = 'dna (like 16S) or prot (like mcrA)', choices = ['prot','dna'], required = True)
parser.add_argument('-m', metavar = 'hmm_file', type = str, nargs = 1, help = 'HMM file', required = True)
parser.add_argument('-e', metavar = 'evalue', type = str, nargs = 1, help = 'evalue cutoff for the hmmsearch', default = [''])
parser.add_argument('-jpplacer', metavar = 'threads', type = str, nargs = 1, help = 'number of threads to use when pplacing (default = 5)', default = [5])
parser.add_argument('-jhmm', metavar = 'threads', type = str, nargs = 1, help = 'number of threads to use when hmmsearching (default = 5)', default = [5])
parser.add_argument('-c', metavar = 'reference_package', type = str, nargs = 1, help = 'Reference package of gene family' , default =argparse.SUPPRESS)
parser.add_argument('-g', metavar = 'gg_database', type = str, nargs = 1, help = 'Aligned gg database for pynast alignment (dna sequences only)', default = argparse.SUPPRESS)
parser.add_argument('-o', metavar = 'output directory', type = str, nargs = 1, help = 'Specify an output directory (default is the file name) If you are looking for more than one marker gene in the same directory, you will definitely need this flag to avoid clobbering.', default = argparse.SUPPRESS)
parser.add_argument('-v', action = 'version', version = 'graftM v.0.1')

cl=parser.parse_args()


if cl.e[0]:
  cl.e[0] = '-E '+cl.e[0]
else:
  pass
if cl.jpplacer[0]:
  cl.jpplacer[0] =  '-j '+str(cl.jpplacer[0])
else:
  pass
if cl.jhmm[0]:
  cl.jhmm[0] = '--cpu '+str(cl.jhmm[0])
else:
  pass

##### Functions #####

# splits fasta file for hmmaligning
def fasta_parser(to_split):

  num_seqs = 1
  all_fasta = list(SeqIO.parse(to_split, 'fasta'))
  num_files = int(math.ceil(len(all_fasta)/float(num_seqs)))
  i = 1
  while i <= num_files:
    start = int(i-1) * int(num_seqs)
    end = int(i) * int(num_seqs)
    filename = to_split.split('.')[:-1][0] + '_' + str(i) + '.g.fasta'
    SeqIO.write(all_fasta[start:end], filename, 'fasta')
    i += 1

# Displays message with time in brackets before the message.
def message(message):
  time = datetime.now().strftime('%H:%M:%S')
  print '['+time+']: '+message
# run nhmmer
def nhmmer(hmm, raw_seq_file):
  fa_match = re.search('\.fa$', raw_seq_file)
  faa_match = re.search('\.faa$', raw_seq_file)
  fq_gz_match = re.search('\.fq\.gz$', raw_seq_file)
  fastq_gz_match = re.search('\.fastq\.gz$', raw_seq_file)
  fna_match = re.search('\.fna$', raw_seq_file)
  path = './'+replace_name(raw_seq_file, '')+'.1.hmmout.csv'
  if os.path.isfile(path) == True:
    hmmout_table_title = replace_name(raw_seq_file, '.2.hmmout.csv')
    if fa_match or fna_match or faa_match:
      subprocess.check_call(["/bin/bash", "-c", " nhmmer "+cl.jhmm[0]+" "+cl.e[0]+" --tblout " +hmmout_table_title+ " " +hmm+ " <(sed 's/:/$/g' " +raw_seq_file+ ") 2>&1 > /dev/null"])
    if fq_gz_match or fastq_gz_match:
      subprocess.check_call(["/bin/bash", "-c", " nhmmer "+cl.jhmm[0]+" "+cl.e[0]+" --tblout " +hmmout_table_title+ " " +hmm+ " <(awk '{print \">\" substr($0,2);getline;print;getline;getline}' <(zcat " +raw_seq_file+ " | sed 's/:/$/g')) 2>&1 > /dev/null"])
  elif os.path.isfile(path) == False:
    hmmout_table_title = replace_name(raw_seq_file, '.1.hmmout.csv')
    if fa_match or fna_match or faa_match:
      subprocess.check_call(["/bin/bash", "-c", " nhmmer "+cl.jhmm[0]+" "+cl.e[0]+" --tblout " +hmmout_table_title+ " " +hmm+ " <(sed 's/:/$/g' " +raw_seq_file+ ") 2>&1 > /dev/null"])
    if fq_gz_match or fastq_gz_match:
      subprocess.check_call(["/bin/bash", "-c", " nhmmer "+cl.jhmm[0]+" "+cl.e[0]+" --tblout " +hmmout_table_title+ " " +hmm+ " <(awk '{print \">\" substr($0,2);getline;print;getline;getline}' <(zcat " +raw_seq_file+ " | sed 's/:/$/g')) 2>&1 > /dev/null"])
  else:
    message('ERROR: Suffix on %s not recegnised. Please submit an .fq.gz or .fa file\n' % (raw_seq_file))
    exit(1)

# split_names
def title_cleaner(title):
  d = title.split('_')
  del d[-1]
  return '_'.join(d)

# run hmmsearch
def hmmsearch(hmm, raw_seq_file):
  fa_match = re.search('\.fa$', raw_seq_file)
  fq_gz_match = re.search('\.fq\.gz$', raw_seq_file)
  faa_match = re.search('\.faa$', raw_seq_file)
  fna_match = re.search('\.fna$', raw_seq_file)
  fastq_gz_match = re.search('\.fastq\.gz$', raw_seq_file)
  path = './'+replace_name(raw_seq_file, '')+'.1.hmmout.csv'
  if os.path.isfile(path) == True:
    hmmout_table_title = replace_name(raw_seq_file, '.2.hmmout.csv')
    if fa_match or fna_match or faa_match:
      subprocess.check_call(["/bin/bash", "-c", " hmmsearch "+cl.jhmm[0]+" "+cl.e[0]+" --domtblout " +hmmout_table_title+ " " +hmm+ " <(getorf -sequence  <(sed 's/:/$/g' " +raw_seq_file+ ") -outseq >(cat) -minsize 98 2>/dev/null) 2>&1 > /dev/null"])
      return
    if fq_gz_match or fastq_gz_match:
      subprocess.check_call(["/bin/bash", "-c", " hmmsearch "+cl.jhmm[0]+" "+cl.e[0]+" --domtblout " +hmmout_table_title+ " " +hmm+ " <(getorf -sequence <(awk '{print \">\" substr($0,2);getline;print;getline;getline}' <(zcat " +raw_seq_file+ " | sed 's/:/$/g')) \
      -outseq >(cat) -minsize 98 2>/dev/null) 2>&1 > /dev/null"])
      return
    else:
      message('ERROR: Suffix on %s not recegnised. Please submit an .fq.gz or .fa file\n' % (raw_seq_file))
      exit(1)
  else:
    hmmout_table_title = replace_name(raw_seq_file, '.1.hmmout.csv')
    if fa_match or fna_match or faa_match:
      subprocess.check_call(["/bin/bash", "-c", " hmmsearch "+cl.jhmm[0]+" "+cl.e[0]+" --domtblout " +hmmout_table_title+ " " +hmm+ " <(getorf -sequence  <(sed 's/:/$/g' " +raw_seq_file+ ") -outseq >(cat) -minsize 98 2>/dev/null) 2>&1 > /dev/null"])
      return
    if fq_gz_match or fastq_gz_match:
      subprocess.check_call(["/bin/bash", "-c", " hmmsearch "+cl.jhmm[0]+" "+cl.e[0]+" --domtblout " +hmmout_table_title+ " " +hmm+ " <(getorf -sequence <(awk '{print \">\" substr($0,2);getline;print;getline;getline}' <(zcat " +raw_seq_file+ " | sed 's/:/$/g')) \
      -outseq >(cat) -minsize 98 2>/dev/null) 2>&1 > /dev/null"])
      return
    else:
      message('ERROR: Suffix on %s not recegnised. Please submit an .fq.gz or .fa file\n' % (raw_seq_file))
      exit(1)

# run pynast
def pynast(ts_file, gg_db_path):
  subprocess.check_call('pynast -l 0 -i ' +replace_name(ts_file, '.ts.fasta')+ ' -t ' +gg_db_path+ ' -a ' +replace_name(ts_file, '.aln.fasta'), shell=True)

# run pplacer
def pplacer(refpkg, ts_file):
  subprocess.check_call('pplacer '+cl.jpplacer[0]+' --verbosity 0 -c ' +refpkg+ ' ' +ts_file, shell=True)

# run guppy classify
def guppy_class(rpkg, jplace_file):
  subprocess.check_call('guppy classify -c ' +rpkg+ ' '+jplace_file+' > ' +replace_name(jplace_file, '.guppy'), shell=True)

  # HMM aligning
def hmmalign(hmm, sequencefile):
  base_name = replace_name(sequencefile, '')
  try:
    str(cl.o[0])
    subprocess.check_call("mkdir "+ cl.o[0], shell=True)
  except:
    subprocess.check_call("mkdir "+ base_name, shell = True)
  try:
    str(cl.o[0])
    subprocess.check_call("mv "+base_name+".* "+cl.o[0], shell = True)
  except:
    subprocess.check_call("mv " +base_name+".*  "+replace_name(cl.f[0], ''), shell = True)
  if cl.t[0] == 'prot':
    try:
      str(cl.o[0])
      fasta_parser((cl.o[0]+'/'+replace_name(sequencefile, '.orf.fasta')))
    except:
      fasta_parser((replace_name(cl.f[0], '')+'/'+replace_name(sequencefile, '.orf.fasta')))

  elif cl.t[0] == 'dna':
    try:
      fasta_parser((cl.o[0]+'/'+replace_name(sequencefile, '.ts.fasta')))
    except:
      fasta_parser((replace_name(cl.f[0], '')+'/'+replace_name(sequencefile, '.ts.fasta')))

  path = './'+out_file_name+'/*.g.fasta'
  files = glob.glob(path)
  for file in files:
    subprocess.check_call('hmmalign --trim -o '+file+'.sto ' +hmm+ ' ' +file, shell = True)
  path = './'+out_file_name+'/*.sto'
  files = glob.glob(path)
  for file in files:
    subprocess.check_call('seqmagick convert ' +file+ ' ' +file+'conv_.fa', shell=True)
  path = './'+out_file_name+'/*conv_.fa'
  files = glob.glob(path)
  for file in files:
    subprocess.check_call("sed 's/[a-z]//g' " +file+ " > " +file+'.ready', shell=True)
  try:
    str(cl.o[0])
    subprocess.check_call("rm "+cl.o[0]+"/*.sto "+cl.o[0]+"/*conv_.fa "+cl.o[0]+"/*.fasta", shell=True)
  except:
    subprocess.check_call("rm "+base_name+"/*.sto "+base_name+"/*conv_.fa "+base_name+"/*.fasta", shell=True)
  path = './'+out_file_name+'/*.ready'
  files = glob.glob(path)
  out_aligned_name = replace_name(sequencefile, '.aln.fasta')
  title_file_open = open(out_aligned_name, 'w')
  for file in files:
    for line in open(file):
      title_file_open.write(line)
  title_file_open.close()
  subprocess.check_call('rm '+out_file_name+'/*.ready', shell=True)

# process hmmsearch/nhmmer results into 'ts_file's
def csv_to_titles_for(hmmout, type_, raw_seq_file):
  raw_titles = []
  line_counter = 0
  for line in open(hmmout):
    match = re.search('^\#', line)
    if match:
      continue
    else:
      line_counter += 1
      split = line.split(' ', 1)
      title = str(split[0])
      if type_ == 'dna':
        raw_titles.append(title.replace('$',':'))
      if type_ == 'prot':
        if 'FCC' in line:
          raw_titles.append(title_cleaner(title).replace('$',':').replace('_', '/'))
        else:
          raw_titles.append(title_cleaner(title).replace('$',':'))
  if line_counter == 0:
    message('0 Reads found!')
    exit(1)
  else:
    message('Found %s read(s) in %s.' % (str(line_counter), replace_name(raw_seq_file, '')))
  file_name = replace_name(hmmout, '.titles.1.txt')
  title_file_open = open(file_name, 'w')
  for title in raw_titles:
    title = str(title) + '\n'
    title_file_open.write(title)
  title_file_open.close()

def csv_to_titles_rev(hmmout, type_, raw_seq_file):
  raw_titles = []
  line_counter = 0
  for line in open(hmmout):
    match = re.search('^\#', line)
    if match:
      continue
    else:
      line_counter += 1
      split = line.split(' ', 1)
      title = str(split[0])
      if type_ == 'dna':
        raw_titles.append(title).replace('$',':')
      if type_ == 'prot':
        if 'FCC' in line:
          raw_titles.append(title_cleaner(title).replace('$',':').replace('_', '/'))
        else:
          raw_titles.append(title_cleaner(title).replace('$',':'))
  if line_counter == 0:
    message('0 Reads found!')
    exit(1)
  else:
    message('Found %s read(s) in %s.' % (str(line_counter), replace_name(raw_seq_file, '')))
  file_name = replace_name(hmmout, '.titles.2.txt')
  title_file_open = open(file_name, 'w')
  for title in raw_titles:
    title = str(title) + '\n'
    title_file_open.write(title)
  title_file_open.close()

def extract_from_raw_reads(raw_seq_file, hmm):
  fa_match = re.search('\.fa$', raw_seq_file)
  fq_gz_match = re.search('\.fq\.gz$', raw_seq_file)
  faa_match = re.search('\.faa$', raw_seq_file)
  fna_match = re.search('\.fna$', raw_seq_file)
  fastq_gz_match = re.search('\.fastq\.gz$', raw_seq_file)
  all_titles = []
  for_titles = []
  file_name = replace_name(raw_seq_file, '.titles.txt')
  x = open('./'+replace_name(cl.f[0], '')+'.titles.1.txt', 'r')
  for line in x:
    for_titles.append(line)
  x.close()
  try:
    x = open('./'+replace_name(cl.f[0], '')+'.titles.2.txt', 'r')
    for line in x:
      if line in for_titles:
        all_titles.append(line)
    x.close()
  except IOError:
    all_titles = for_titles
  title_file_open = open(file_name, 'w')
  for x in all_titles:
    title_file_open.write(x)
  title_file_open.close()
  file_name = replace_name(raw_seq_file, '.ts')
  if fa_match or faa_match or fna_match:
    message('Extracting reads..')
    subprocess.check_call("fxtract -H -f " +replace_name(raw_seq_file, '.titles.txt')+ " " +raw_seq_file+ " > " +file_name+ " ", shell=True)
  elif fq_gz_match or fastq_gz_match:
    message('Extracting reads..')
    subprocess.check_call("fxtract -H -f " +replace_name(raw_seq_file, '.titles.txt')+ " " +raw_seq_file+ " | awk '{print \">\" substr($0,2);getline;print;getline;getline}' > " +file_name+ " ", shell=True)
  file_name2 = replace_name(raw_seq_file, '.ts.fasta')
  fasta_file_open = open(file_name2, 'w')
  for line in open(file_name):
    if '>' in line:
      line = line.replace(':', '_')
      fasta_file_open.write(line)
    else:
      line = line
      fasta_file_open.write(line)
  fasta_file_open.close()
  file_name = replace_name(raw_seq_file, '.ts')
  file_name2 = replace_name(raw_seq_file, '.ts.fasta')
  fasta_file_open = open(file_name2, 'w')
  for line in open(file_name):
    if '>' in line:
      line = line.replace(':', '_')
      fasta_file_open.write(line)
    else:
      fasta_file_open.write(line)
  fasta_file_open.close()
  if cl.t[0] == 'dna':
    return
  raw_orf_title = replace_name(raw_seq_file, '.orf')
  subprocess.check_call('getorf -sequence ' +file_name2+ ' -outseq ' +raw_orf_title+ ' -minsize 98 2>/dev/null', shell=True)
  hmm_out_title = replace_name(raw_seq_file, '.tmp.csv')
  subprocess.check_call("hmmsearch --tblout "+hmm_out_title+" "+hmm+" "+raw_orf_title+" 2>&1 > /dev/null", shell=True)
  raw_titles = []
  for line in open(hmm_out_title):
    hmm_table_parser = re.search('^#', line)
    if hmm_table_parser:
      continue
    else:
      split = line.split(' ', 1)
      raw_titles.append(split[0])
  file_name = replace_name(raw_seq_file, '.orf.titles')
  title_file_open = open(file_name, 'w')
  for title in raw_titles:
    title = str(title) + '\n'
    title_file_open.write(title)
  title_file_open.close()
  hmm_out_title = replace_name(raw_seq_file, '.orf.fasta')
  subprocess.check_call('fxtract -H -f '+file_name+' '+raw_orf_title+' > '+hmm_out_title, shell=True)

def replace_name(old_title,new_suffix):
  if '/' in old_title:
    split = old_title.split('/')
    title2 = split[len(split) - 1]
    if '.' in title2:
      split = title2.split('.')
      return split[0] + new_suffix
    else:
      return 'Suffix on '+old_title+' not recognized.'
  else:
    if '.' in old_title:
      split = old_title.split('.')
      return split[0] + new_suffix
    else:
      return old_title

def gg_formatter(read_name, classification):
  ids = ['k_','p_','c_','o_','f_','g_','s_','i_']
  classification.remove(classification[0])
  for x in range(0, 7):
    try:
      classification[x] = ids[x]+classification[x]
    except:
      classification.append(ids[x])
  return classification

 ##### Running Script #####

print intro
seq_file_title = replace_name(cl.f[0], '')
hmm_file_title = replace_name(cl.m[0], '.hmm')

try:
  str(cl.o[0])
  out_file_name = cl.o[0]
except AttributeError:
  out_file_name = replace_name(cl.f[0], '')

try:
  str(cl.r[0])
  if replace_name(cl.f[0], '') != replace_name(cl.r[0], ''):
    message("Looks like the forward reads don't match the reverse reads. Please make sure you're using the right ones!")
    exit(1)
  else:
    pass
except AttributeError:
  pass

if cl.t[0] == 'prot':
  date = datetime.now().strftime('%Y/%m/%d')
  message(str(date))
  message('Searching %s using %s..' % (seq_file_title, hmm_file_title))
  hmmsearch(cl.m[0], cl.f[0])
  csv_to_titles_for(replace_name(cl.f[0], '.1.hmmout.csv'), cl.t[0], cl.f[0])
  try:
    hmmsearch(cl.m[0], cl.r[0])
    csv_to_titles_rev(replace_name(cl.r[0], '.2.hmmout.csv'), cl.t[0], cl.f[0])
  except AttributeError:
    message('No reverse read found. Continuing with forward read only..')
  extract_from_raw_reads(cl.f[0], cl.m[0])
  message('Aligning to hmm..')
  hmmalign(cl.m[0], replace_name(cl.f[0], '.ts.fasta'))
  try:
    str(cl.c[0])
    message('Placing in refpkg tree..')
    pplacer(cl.c[0], replace_name(cl.f[0], '.aln.fasta'))
    message('Creating Guppy file..')
    guppy_class(cl.c[0], replace_name(cl.f[0],'.aln.jplace'))
  except AttributeError:
    message('No refpkg found! Stopping at alignment')
    exit(1)


if cl.t[0] == 'dna':
  date = datetime.now().strftime('%Y-%m-%d')
  message(date)
  message('Searching %s using %s..' % (seq_file_title, hmm_file_title))
  nhmmer(cl.m[0], cl.f[0])
  csv_to_titles_for(replace_name(cl.f[0], '.1.hmmout.csv'), cl.t[0], cl.f[0])
  try:
    nhmmer(cl.m[0], cl.r[0])
    csv_to_titles_rev(replace_name(cl.r[0], '.2.hmmout.csv'), cl.t[0], cl.f[0])
  except AttributeError:
    message('No reverse read found. Continuing with forward read only..')
  extract_from_raw_reads(cl.f[0], cl.m[0])
  message('Aligning to hmm..')
  pynast(cl.f[0], cl.g[0])
  try:
    str(cl.c[0])
    message('Placing in refpkg tree..')
    pplacer(cl.c[0], replace_name(cl.f[0],'.aln.fasta'))
    message('Creating Guppy file..')
    guppy_class(cl.c[0], replace_name(cl.f[0], '.aln.jplace'))
  except AttributeError:
    message('No refpkg found! Stopping at alignment')
    exit(1)

d = {
}
test = 1
message('Creating dictionary..')
for line in open(glob.glob(replace_name(cl.f[0],'.guppy'))[0], 'r'):
  splitline = line.split(' ')
  list = [x for x in splitline if x]
  if list[0] != 'name' and list[0] not in d:
    d[list[0]] = []
message('Filling dictionary..')
for x,y in d.iteritems():
  for line in open(glob.glob(replace_name(cl.f[0],'.guppy'))[0], 'r'):
    splitline = line.split(' ')
    list = [n for n in splitline if n]
    if x == list[0]:
      try:
        float(list[4])
        if list[1] == list[2]:
          if float(list[4]) > 0.5:
            d[x].append(list[3])
      except ValueError:
        list.pop(3)
        if list[1] == list[2]:
          if float(list[len(list)-2]) > 0.5:
            d[x].append(list[3])
    else:
      continue
message('Saving dictionary..')
pickle.dump(d, open(replace_name(cl.f[0],'_dict.p'), 'wb'))
message('Dictionary for %s complete..' % (seq_file_title))
message('Building OTU table..')
classifications = []
placed = []

for x,y in d.iteritems():
  if x not in placed:
    classifications.append(';'.join(gg_formatter(x,y)))
    placed.append(x)
  else:
    continue

otu_id = 0
output_table = []
unique_list = []
output_table.append('#OTU_ID\t'+replace_name(cl.f[0], '')+'\tConsensusLineage')
for x in classifications:
  if x not in unique_list:
    unique_list.append(x)
for x in unique_list:
  output_table.append([str(otu_id),str(classifications.count(x)),x])
  otu_id += 1

otu_table = open(replace_name(cl.f[0], '_otu_table.txt'), 'w')
for line in output_table:
  if '#' in line:
    otu_table.write(line+'\n')
  else: otu_table.write('\t'.join(line)+'\n')
otu_table.close()

try:
  str(cl.o[0])
  subprocess.call("mv "+replace_name(cl.f[0], '')+"* "+cl.o[0]+"/ 2> /dev/null", shell = True)
except:
  subprocess.call("mv "+replace_name(cl.f[0], '')+"* "+replace_name(cl.f[0], '')+"/ 2> /dev/null", shell = True)

message('Finshed! Thank you for using graftM! \n')

exit(1)
